{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ESDS_GoT_LFQA_via_Haystack.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/superchargez/haystack/blob/tutorials/ESDS_GoT_LFQA_via_Haystack.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEH-CRbeA6NU"
      },
      "source": [
        "# Long-Form Question Answering\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/deepset-ai/haystack/blob/master/tutorials/Tutorial12_LFQA.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3K27Y5FbA6NV"
      },
      "source": [
        "### Prepare environment\n",
        "\n",
        "#### Colab: Enable the GPU runtime\n",
        "Make sure you enable the GPU runtime to experience decent speed in this tutorial.  \n",
        "**Runtime -> Change Runtime type -> Hardware accelerator -> GPU**\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/deepset-ai/haystack/master/docs/_src/img/colab_gpu_runtime.jpg\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlZgP8q1A6NW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b25ebc77-45f3-49b0-e516-886204bbd6d9"
      },
      "source": [
        "# Make sure you have a GPU running\n",
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Nov  4 09:07:52 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   46C    P8    28W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NM36kbRFA6Nc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "eabf4929-9640-4768-e1c7-5e98e1691d87"
      },
      "source": [
        "# Install the latest master of Haystack\n",
        "!pip install git+https://github.com/deepset-ai/haystack.git\n",
        "\n",
        "# If you run this notebook on Google Colab, you might need to\n",
        "# restart the runtime after installing haystack."
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/deepset-ai/haystack.git\n",
            "  Cloning https://github.com/deepset-ai/haystack.git to /tmp/pip-req-build-0k4fkbmz\n",
            "  Running command git clone -q https://github.com/deepset-ai/haystack.git /tmp/pip-req-build-0k4fkbmz\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from farm-haystack==1.0.0rc1) (57.4.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from farm-haystack==1.0.0rc1) (0.37.0)\n",
            "Requirement already satisfied: torch<1.10,>1.5 in /usr/local/lib/python3.7/dist-packages (from farm-haystack==1.0.0rc1) (1.9.0+cu111)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from farm-haystack==1.0.0rc1) (4.62.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from farm-haystack==1.0.0rc1) (2.23.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.7/dist-packages (from farm-haystack==1.0.0rc1) (1.4.1)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from farm-haystack==1.0.0rc1) (0.0)\n",
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 1.1 MB/s \n",
            "\u001b[?25hCollecting mlflow<=1.13.1\n",
            "  Downloading mlflow-1.13.1-py3-none-any.whl (14.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.1 MB 30 kB/s \n",
            "\u001b[?25hCollecting transformers==4.7.0\n",
            "  Downloading transformers-4.7.0-py3-none-any.whl (2.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5 MB 33.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from farm-haystack==1.0.0rc1) (0.3.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from farm-haystack==1.0.0rc1) (5.4.8)\n",
            "Collecting fastapi\n",
            "  Downloading fastapi-0.70.0-py3-none-any.whl (51 kB)\n",
            "\u001b[K     |████████████████████████████████| 51 kB 22 kB/s \n",
            "\u001b[?25hCollecting uvicorn\n",
            "  Downloading uvicorn-0.15.0-py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 2.8 MB/s \n",
            "\u001b[?25hCollecting gunicorn\n",
            "  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 7.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from farm-haystack==1.0.0rc1) (1.1.5)\n",
            "Collecting elasticsearch<=7.10,>=7.7\n",
            "  Downloading elasticsearch-7.10.0-py2.py3-none-any.whl (321 kB)\n",
            "\u001b[K     |████████████████████████████████| 321 kB 47.3 MB/s \n",
            "\u001b[?25hCollecting elastic-apm\n",
            "  Downloading elastic_apm-6.6.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (351 kB)\n",
            "\u001b[K     |████████████████████████████████| 351 kB 49.4 MB/s \n",
            "\u001b[?25hCollecting tox\n",
            "  Downloading tox-3.24.4-py2.py3-none-any.whl (85 kB)\n",
            "\u001b[K     |████████████████████████████████| 85 kB 4.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: coverage in /usr/local/lib/python3.7/dist-packages (from farm-haystack==1.0.0rc1) (3.7.1)\n",
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[K     |████████████████████████████████| 981 kB 31.8 MB/s \n",
            "\u001b[?25hCollecting pytesseract==0.3.7\n",
            "  Downloading pytesseract-0.3.7.tar.gz (13 kB)\n",
            "Collecting pillow==8.3.2\n",
            "  Downloading Pillow-8.3.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0 MB 31.5 MB/s \n",
            "\u001b[?25hCollecting pdf2image==1.14.0\n",
            "  Downloading pdf2image-1.14.0-py3-none-any.whl (10 kB)\n",
            "Collecting sentence-transformers>=0.4.0\n",
            "  Downloading sentence-transformers-2.1.0.tar.gz (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 6.5 MB/s \n",
            "\u001b[?25hCollecting python-multipart\n",
            "  Downloading python-multipart-0.0.5.tar.gz (32 kB)\n",
            "Collecting python-docx\n",
            "  Downloading python-docx-0.8.11.tar.gz (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 32.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.7/dist-packages (from farm-haystack==1.0.0rc1) (1.4.25)\n",
            "Collecting sqlalchemy_utils\n",
            "  Downloading SQLAlchemy_Utils-0.37.9-py3-none-any.whl (100 kB)\n",
            "\u001b[K     |████████████████████████████████| 100 kB 7.5 MB/s \n",
            "\u001b[?25hCollecting faiss-cpu>=1.6.3\n",
            "  Downloading faiss_cpu-1.7.1.post2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.4 MB 35.7 MB/s \n",
            "\u001b[?25hCollecting tika\n",
            "  Downloading tika-1.24.tar.gz (28 kB)\n",
            "Collecting httptools\n",
            "  Downloading httptools-0.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (402 kB)\n",
            "\u001b[K     |████████████████████████████████| 402 kB 43.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from farm-haystack==1.0.0rc1) (3.2.5)\n",
            "Requirement already satisfied: more_itertools in /usr/local/lib/python3.7/dist-packages (from farm-haystack==1.0.0rc1) (8.10.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from farm-haystack==1.0.0rc1) (2.6.3)\n",
            "Collecting pymilvus\n",
            "  Downloading pymilvus-1.1.2-py3-none-any.whl (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 4.3 MB/s \n",
            "\u001b[?25hCollecting SPARQLWrapper\n",
            "  Downloading SPARQLWrapper-1.8.5-py3-none-any.whl (26 kB)\n",
            "Collecting mmh3\n",
            "  Downloading mmh3-3.0.0-cp37-cp37m-manylinux2010_x86_64.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 6.7 MB/s \n",
            "\u001b[?25hCollecting weaviate-client==2.5.0\n",
            "  Downloading weaviate_client-2.5.0-py3-none-any.whl (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 4.7 MB/s \n",
            "\u001b[?25hCollecting ray==1.5.0\n",
            "  Downloading ray-1.5.0-cp37-cp37m-manylinux2014_x86_64.whl (51.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 51.5 MB 58 kB/s \n",
            "\u001b[?25hCollecting dataclasses-json\n",
            "  Downloading dataclasses_json-0.5.6-py3-none-any.whl (25 kB)\n",
            "Collecting quantulum3\n",
            "  Downloading quantulum3-0.7.9-py3-none-any.whl (10.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.7 MB 9.3 MB/s \n",
            "\u001b[?25hCollecting psycopg2-binary\n",
            "  Downloading psycopg2_binary-2.9.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 38.3 MB/s \n",
            "\u001b[?25hCollecting uvloop==0.14\n",
            "  Downloading uvloop-0.14.0-cp37-cp37m-manylinux2010_x86_64.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 39.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.28.1 in /usr/local/lib/python3.7/dist-packages (from ray==1.5.0->farm-haystack==1.0.0rc1) (1.41.0)\n",
            "Collecting gpustat\n",
            "  Downloading gpustat-0.6.0.tar.gz (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 6.2 MB/s \n",
            "\u001b[?25hCollecting aiohttp\n",
            "  Downloading aiohttp-3.8.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 47.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from ray==1.5.0->farm-haystack==1.0.0rc1) (3.13)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray==1.5.0->farm-haystack==1.0.0rc1) (2.6.0)\n",
            "Collecting redis>=3.5.0\n",
            "  Downloading redis-3.5.3-py2.py3-none-any.whl (72 kB)\n",
            "\u001b[K     |████████████████████████████████| 72 kB 557 kB/s \n",
            "\u001b[?25hRequirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray==1.5.0->farm-haystack==1.0.0rc1) (1.0.2)\n",
            "Requirement already satisfied: prometheus-client>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from ray==1.5.0->farm-haystack==1.0.0rc1) (0.12.0)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from ray==1.5.0->farm-haystack==1.0.0rc1) (1.19.5)\n",
            "Collecting pydantic>=1.8\n",
            "  Downloading pydantic-1.8.2-cp37-cp37m-manylinux2014_x86_64.whl (10.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1 MB 44.8 MB/s \n",
            "\u001b[?25hCollecting py-spy>=0.2.0\n",
            "  Downloading py_spy-0.3.10-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (3.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2 MB 19.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from ray==1.5.0->farm-haystack==1.0.0rc1) (3.3.0)\n",
            "Collecting aiohttp-cors\n",
            "  Downloading aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)\n",
            "Collecting aioredis\n",
            "  Downloading aioredis-2.0.0-py3-none-any.whl (69 kB)\n",
            "\u001b[K     |████████████████████████████████| 69 kB 7.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray==1.5.0->farm-haystack==1.0.0rc1) (7.1.2)\n",
            "Collecting opencensus\n",
            "  Downloading opencensus-0.8.0-py2.py3-none-any.whl (128 kB)\n",
            "\u001b[K     |████████████████████████████████| 128 kB 52.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.15.3 in /usr/local/lib/python3.7/dist-packages (from ray==1.5.0->farm-haystack==1.0.0rc1) (3.17.3)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Collecting huggingface-hub==0.0.8\n",
            "  Downloading huggingface_hub-0.0.8-py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0->farm-haystack==1.0.0rc1) (21.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0->farm-haystack==1.0.0rc1) (4.8.1)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 40.6 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 39.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0->farm-haystack==1.0.0rc1) (2019.12.20)\n",
            "Collecting validators>=0.18.2\n",
            "  Downloading validators-0.18.2-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: urllib3<2,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from elasticsearch<=7.10,>=7.7->farm-haystack==1.0.0rc1) (1.24.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from elasticsearch<=7.10,>=7.7->farm-haystack==1.0.0rc1) (2021.5.30)\n",
            "Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from grpcio>=1.28.1->ray==1.5.0->farm-haystack==1.0.0rc1) (1.15.0)\n",
            "Collecting azure-storage-blob>=12.0.0\n",
            "  Downloading azure_storage_blob-12.9.0-py2.py3-none-any.whl (356 kB)\n",
            "\u001b[K     |████████████████████████████████| 356 kB 50.6 MB/s \n",
            "\u001b[?25hCollecting databricks-cli>=0.8.7\n",
            "  Downloading databricks-cli-0.16.2.tar.gz (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 6.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from mlflow<=1.13.1->farm-haystack==1.0.0rc1) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from mlflow<=1.13.1->farm-haystack==1.0.0rc1) (2.8.2)\n",
            "Collecting gitpython>=2.1.0\n",
            "  Downloading GitPython-3.1.24-py3-none-any.whl (180 kB)\n",
            "\u001b[K     |████████████████████████████████| 180 kB 42.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from mlflow<=1.13.1->farm-haystack==1.0.0rc1) (0.3)\n",
            "Collecting querystring-parser\n",
            "  Downloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n",
            "Requirement already satisfied: sqlparse>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from mlflow<=1.13.1->farm-haystack==1.0.0rc1) (0.4.2)\n",
            "Collecting alembic<=1.4.1\n",
            "  Downloading alembic-1.4.1.tar.gz (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 49.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Flask in /usr/local/lib/python3.7/dist-packages (from mlflow<=1.13.1->farm-haystack==1.0.0rc1) (1.1.4)\n",
            "Collecting docker>=4.0.0\n",
            "  Downloading docker-5.0.3-py2.py3-none-any.whl (146 kB)\n",
            "\u001b[K     |████████████████████████████████| 146 kB 45.2 MB/s \n",
            "\u001b[?25hCollecting prometheus-flask-exporter\n",
            "  Downloading prometheus_flask_exporter-0.18.5-py3-none-any.whl (17 kB)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.1.5-py2.py3-none-any.whl (75 kB)\n",
            "\u001b[K     |████████████████████████████████| 75 kB 2.7 MB/s \n",
            "\u001b[?25hCollecting python-editor>=0.3\n",
            "  Downloading python_editor-1.0.4-py3-none-any.whl (4.9 kB)\n",
            "Collecting msrest>=0.6.21\n",
            "  Downloading msrest-0.6.21-py2.py3-none-any.whl (85 kB)\n",
            "\u001b[K     |████████████████████████████████| 85 kB 4.0 MB/s \n",
            "\u001b[?25hCollecting azure-core<2.0.0,>=1.10.0\n",
            "  Downloading azure_core-1.19.1-py2.py3-none-any.whl (176 kB)\n",
            "\u001b[K     |████████████████████████████████| 176 kB 51.6 MB/s \n",
            "\u001b[?25hCollecting cryptography>=2.1.4\n",
            "  Downloading cryptography-35.0.0-cp36-abi3-manylinux_2_24_x86_64.whl (3.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 37.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=2.1.4->azure-storage-blob>=12.0.0->mlflow<=1.13.1->farm-haystack==1.0.0rc1) (1.14.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=2.1.4->azure-storage-blob>=12.0.0->mlflow<=1.13.1->farm-haystack==1.0.0rc1) (2.20)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.7/dist-packages (from databricks-cli>=0.8.7->mlflow<=1.13.1->farm-haystack==1.0.0rc1) (0.8.9)\n",
            "Collecting websocket-client>=0.32.0\n",
            "  Downloading websocket_client-1.2.1-py2.py3-none-any.whl (52 kB)\n",
            "\u001b[K     |████████████████████████████████| 52 kB 1.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from gitpython>=2.1.0->mlflow<=1.13.1->farm-haystack==1.0.0rc1) (3.7.4.3)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 936 kB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Collecting isodate>=0.6.0\n",
            "  Downloading isodate-0.6.0-py2.py3-none-any.whl (45 kB)\n",
            "\u001b[K     |████████████████████████████████| 45 kB 3.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests-oauthlib>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from msrest>=0.6.21->azure-storage-blob>=12.0.0->mlflow<=1.13.1->farm-haystack==1.0.0rc1) (1.3.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->farm-haystack==1.0.0rc1) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->farm-haystack==1.0.0rc1) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.21->azure-storage-blob>=12.0.0->mlflow<=1.13.1->farm-haystack==1.0.0rc1) (3.1.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence-transformers>=0.4.0->farm-haystack==1.0.0rc1) (0.10.0+cu111)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence-transformers>=0.4.0->farm-haystack==1.0.0rc1) (0.22.2.post1)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 41.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.4.2->farm-haystack==1.0.0rc1) (1.1.2)\n",
            "Requirement already satisfied: decorator>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from validators>=0.18.2->weaviate-client==2.5.0->farm-haystack==1.0.0rc1) (4.4.2)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-5.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (160 kB)\n",
            "\u001b[K     |████████████████████████████████| 160 kB 48.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->ray==1.5.0->farm-haystack==1.0.0rc1) (21.2.0)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (192 kB)\n",
            "\u001b[K     |████████████████████████████████| 192 kB 48.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->ray==1.5.0->farm-haystack==1.0.0rc1) (2.0.7)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 48.5 MB/s \n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.0-py3-none-any.whl (6.1 kB)\n",
            "Collecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting typing-inspect>=0.4.0\n",
            "  Downloading typing_inspect-0.7.1-py3-none-any.whl (8.4 kB)\n",
            "Collecting marshmallow-enum<2.0.0,>=1.5.1\n",
            "  Downloading marshmallow_enum-1.5.1-py2.py3-none-any.whl (4.2 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.3.0\n",
            "  Downloading marshmallow-3.14.0-py3-none-any.whl (47 kB)\n",
            "\u001b[K     |████████████████████████████████| 47 kB 4.2 MB/s \n",
            "\u001b[?25hCollecting mypy-extensions>=0.3.0\n",
            "  Downloading mypy_extensions-0.4.3-py2.py3-none-any.whl (4.5 kB)\n",
            "Collecting starlette==0.16.0\n",
            "  Downloading starlette-0.16.0-py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 288 kB/s \n",
            "\u001b[?25hCollecting anyio<4,>=3.0.0\n",
            "  Downloading anyio-3.3.4-py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 6.4 MB/s \n",
            "\u001b[?25hCollecting sniffio>=1.1\n",
            "  Downloading sniffio-1.2.0-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask->mlflow<=1.13.1->farm-haystack==1.0.0rc1) (1.0.1)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask->mlflow<=1.13.1->farm-haystack==1.0.0rc1) (2.11.3)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask->mlflow<=1.13.1->farm-haystack==1.0.0rc1) (1.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask->mlflow<=1.13.1->farm-haystack==1.0.0rc1) (2.0.1)\n",
            "Requirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.7/dist-packages (from gpustat->ray==1.5.0->farm-haystack==1.0.0rc1) (7.352.0)\n",
            "Collecting blessings>=1.6\n",
            "  Downloading blessings-1.7-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.7.0->farm-haystack==1.0.0rc1) (3.6.0)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from opencensus->ray==1.5.0->farm-haystack==1.0.0rc1) (1.26.3)\n",
            "Collecting opencensus-context==0.1.2\n",
            "  Downloading opencensus_context-0.1.2-py2.py3-none-any.whl (4.4 kB)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray==1.5.0->farm-haystack==1.0.0rc1) (2018.9)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray==1.5.0->farm-haystack==1.0.0rc1) (1.53.0)\n",
            "Requirement already satisfied: google-auth<2.0dev,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray==1.5.0->farm-haystack==1.0.0rc1) (1.35.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray==1.5.0->farm-haystack==1.0.0rc1) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray==1.5.0->farm-haystack==1.0.0rc1) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray==1.5.0->farm-haystack==1.0.0rc1) (4.7.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.7.0->farm-haystack==1.0.0rc1) (2.4.7)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.21.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray==1.5.0->farm-haystack==1.0.0rc1) (0.4.8)\n",
            "Collecting grpcio>=1.28.1\n",
            "  Downloading grpcio-1.37.1-cp37-cp37m-manylinux2014_x86_64.whl (4.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.2 MB 37.8 MB/s \n",
            "\u001b[?25hCollecting ujson>=2.0.0\n",
            "  Downloading ujson-4.2.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (214 kB)\n",
            "\u001b[K     |████████████████████████████████| 214 kB 30.7 MB/s \n",
            "\u001b[?25hCollecting grpcio-tools<1.38.0,>=1.22.0\n",
            "  Downloading grpcio_tools-1.37.1-cp37-cp37m-manylinux2014_x86_64.whl (2.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5 MB 36.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from python-docx->farm-haystack==1.0.0rc1) (4.2.6)\n",
            "Requirement already satisfied: inflect in /usr/local/lib/python3.7/dist-packages (from quantulum3->farm-haystack==1.0.0rc1) (2.1.0)\n",
            "Collecting num2words\n",
            "  Downloading num2words-0.5.10-py3-none-any.whl (101 kB)\n",
            "\u001b[K     |████████████████████████████████| 101 kB 11.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.7/dist-packages (from num2words->quantulum3->farm-haystack==1.0.0rc1) (0.6.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.7.0->farm-haystack==1.0.0rc1) (1.0.1)\n",
            "Collecting rdflib>=4.0\n",
            "  Downloading rdflib-6.0.2-py3-none-any.whl (407 kB)\n",
            "\u001b[K     |████████████████████████████████| 407 kB 50.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: toml>=0.9.4 in /usr/local/lib/python3.7/dist-packages (from tox->farm-haystack==1.0.0rc1) (0.10.2)\n",
            "Collecting pluggy>=0.12.0\n",
            "  Downloading pluggy-1.0.0-py2.py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: py>=1.4.17 in /usr/local/lib/python3.7/dist-packages (from tox->farm-haystack==1.0.0rc1) (1.10.0)\n",
            "Collecting virtualenv!=20.0.0,!=20.0.1,!=20.0.2,!=20.0.3,!=20.0.4,!=20.0.5,!=20.0.6,!=20.0.7,>=16.0.0\n",
            "  Downloading virtualenv-20.10.0-py2.py3-none-any.whl (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 34.0 MB/s \n",
            "\u001b[?25hCollecting platformdirs<3,>=2\n",
            "  Downloading platformdirs-2.4.0-py3-none-any.whl (14 kB)\n",
            "Collecting backports.entry-points-selectable>=1.0.4\n",
            "  Downloading backports.entry_points_selectable-1.1.0-py2.py3-none-any.whl (6.2 kB)\n",
            "Collecting distlib<1,>=0.3.1\n",
            "  Downloading distlib-0.3.3-py2.py3-none-any.whl (496 kB)\n",
            "\u001b[K     |████████████████████████████████| 496 kB 41.0 MB/s \n",
            "\u001b[?25hCollecting asgiref>=3.4.0\n",
            "  Downloading asgiref-3.4.1-py3-none-any.whl (25 kB)\n",
            "Collecting h11>=0.8\n",
            "  Downloading h11-0.12.0-py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 3.0 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: farm-haystack, pytesseract, alembic, databricks-cli, sentence-transformers, gpustat, langdetect, python-docx, python-multipart, seqeval, tika\n",
            "  Building wheel for farm-haystack (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for farm-haystack: filename=farm_haystack-1.0.0rc1-py3-none-any.whl size=353332 sha256=396ad07dfe47c5a1203aaf543967cbeebb4c380725d1a951794232507b8011b0\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-5cigyjgq/wheels/a7/05/3b/9b33368d9af06a39f8e6af2e97fa2af876e893ade323cfc2c9\n",
            "  Building wheel for pytesseract (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytesseract: filename=pytesseract-0.3.7-py2.py3-none-any.whl size=13954 sha256=3b343ccd1830076b17e74e1cdccdeed597cb8f3d9ff6ddb59e7eed62f20f366f\n",
            "  Stored in directory: /root/.cache/pip/wheels/67/71/6c/7a8c5ca2e699752506999ae7baeb692e2b4fc6488c2cddcb22\n",
            "  Building wheel for alembic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for alembic: filename=alembic-1.4.1-py2.py3-none-any.whl size=158172 sha256=845d6938a2bd419879cbe321e68e37be71ea846106513244c69a3f772bb8b4c7\n",
            "  Stored in directory: /root/.cache/pip/wheels/be/5d/0a/9e13f53f4f5dfb67cd8d245bb7cdffe12f135846f491a283e3\n",
            "  Building wheel for databricks-cli (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for databricks-cli: filename=databricks_cli-0.16.2-py3-none-any.whl size=106811 sha256=a00d0e9813bca0b5d5bb60b79da535044a367a3d2f7dda0775f8ee4722be081d\n",
            "  Stored in directory: /root/.cache/pip/wheels/f4/5c/ed/e1ce20a53095f63b27b4964abbad03e59cf3472822addf7d29\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.1.0-py3-none-any.whl size=121000 sha256=2782541f4ef30932523247b4169a9fd14441212b6252b9b8b4fe778d24e427d3\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/f0/bb/ed1add84da70092ea526466eadc2bfb197c4bcb8d4fa5f7bad\n",
            "  Building wheel for gpustat (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gpustat: filename=gpustat-0.6.0-py3-none-any.whl size=12617 sha256=d61464cb32c05a627cc6d3c46f4e91dc4a1eddbec4d83923b1e78926ca5f68db\n",
            "  Stored in directory: /root/.cache/pip/wheels/e6/67/af/f1ad15974b8fd95f59a63dbf854483ebe5c7a46a93930798b8\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993242 sha256=1cce1d3b212d4e893ad98f25e853cbcca4cca632b448f2d881e91821941075af\n",
            "  Stored in directory: /root/.cache/pip/wheels/c5/96/8a/f90c59ed25d75e50a8c10a1b1c2d4c402e4dacfa87f3aff36a\n",
            "  Building wheel for python-docx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-docx: filename=python_docx-0.8.11-py3-none-any.whl size=184508 sha256=c083558a8803e3f2aae1e190d4805c1abaf54ce09ff4b234cbf157b102e9b28c\n",
            "  Stored in directory: /root/.cache/pip/wheels/f6/6f/b9/d798122a8b55b74ad30b5f52b01482169b445fbb84a11797a6\n",
            "  Building wheel for python-multipart (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-multipart: filename=python_multipart-0.0.5-py3-none-any.whl size=31678 sha256=00c1719c620b5142ebca0ba2696c72813fc67128ba2f985e3d6dcc6d98e549b7\n",
            "  Stored in directory: /root/.cache/pip/wheels/2c/41/7c/bfd1c180534ffdcc0972f78c5758f89881602175d48a8bcd2c\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16181 sha256=8109103c7fff5fc56c60d1b74e1eef245306abaab87730022e1e1bc753555943\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n",
            "  Building wheel for tika (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tika: filename=tika-1.24-py3-none-any.whl size=32891 sha256=d078a51fae3d731fe40e3803a6a74eedf2cf4cee9c197a5c0de84456961d66d8\n",
            "  Stored in directory: /root/.cache/pip/wheels/ec/2b/38/58ff05467a742e32f67f5d0de048fa046e764e2fbb25ac93f3\n",
            "Successfully built farm-haystack pytesseract alembic databricks-cli sentence-transformers gpustat langdetect python-docx python-multipart seqeval tika\n",
            "Installing collected packages: multidict, frozenlist, yarl, sniffio, smmap, isodate, asynctest, async-timeout, aiosignal, websocket-client, tokenizers, sacremoses, python-editor, platformdirs, pillow, opencensus-context, mypy-extensions, msrest, marshmallow, Mako, huggingface-hub, grpcio, gitdb, distlib, cryptography, blessings, backports.entry-points-selectable, azure-core, anyio, aiohttp, virtualenv, validators, ujson, typing-inspect, transformers, starlette, sentencepiece, redis, rdflib, querystring-parser, pydantic, py-spy, prometheus-flask-exporter, pluggy, opencensus, num2words, marshmallow-enum, h11, gunicorn, grpcio-tools, gpustat, gitpython, docker, databricks-cli, colorama, azure-storage-blob, asgiref, alembic, aioredis, aiohttp-cors, weaviate-client, uvloop, uvicorn, tox, tika, sqlalchemy-utils, SPARQLWrapper, seqeval, sentence-transformers, ray, quantulum3, python-multipart, python-docx, pytesseract, pymilvus, psycopg2-binary, pdf2image, mmh3, mlflow, langdetect, httptools, fastapi, faiss-cpu, elasticsearch, elastic-apm, dataclasses-json, farm-haystack\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.41.0\n",
            "    Uninstalling grpcio-1.41.0:\n",
            "      Successfully uninstalled grpcio-1.41.0\n",
            "  Attempting uninstall: pluggy\n",
            "    Found existing installation: pluggy 0.7.1\n",
            "    Uninstalling pluggy-0.7.1:\n",
            "      Successfully uninstalled pluggy-0.7.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pytest 3.6.4 requires pluggy<0.8,>=0.5, but you have pluggy 1.0.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed Mako-1.1.5 SPARQLWrapper-1.8.5 aiohttp-3.8.0 aiohttp-cors-0.7.0 aioredis-2.0.0 aiosignal-1.2.0 alembic-1.4.1 anyio-3.3.4 asgiref-3.4.1 async-timeout-4.0.0 asynctest-0.13.0 azure-core-1.19.1 azure-storage-blob-12.9.0 backports.entry-points-selectable-1.1.0 blessings-1.7 colorama-0.4.4 cryptography-35.0.0 databricks-cli-0.16.2 dataclasses-json-0.5.6 distlib-0.3.3 docker-5.0.3 elastic-apm-6.6.1 elasticsearch-7.10.0 faiss-cpu-1.7.1.post2 farm-haystack-1.0.0rc1 fastapi-0.70.0 frozenlist-1.2.0 gitdb-4.0.9 gitpython-3.1.24 gpustat-0.6.0 grpcio-1.37.1 grpcio-tools-1.37.1 gunicorn-20.1.0 h11-0.12.0 httptools-0.3.0 huggingface-hub-0.0.8 isodate-0.6.0 langdetect-1.0.9 marshmallow-3.14.0 marshmallow-enum-1.5.1 mlflow-1.13.1 mmh3-3.0.0 msrest-0.6.21 multidict-5.2.0 mypy-extensions-0.4.3 num2words-0.5.10 opencensus-0.8.0 opencensus-context-0.1.2 pdf2image-1.14.0 pillow-8.3.2 platformdirs-2.4.0 pluggy-1.0.0 prometheus-flask-exporter-0.18.5 psycopg2-binary-2.9.1 py-spy-0.3.10 pydantic-1.8.2 pymilvus-1.1.2 pytesseract-0.3.7 python-docx-0.8.11 python-editor-1.0.4 python-multipart-0.0.5 quantulum3-0.7.9 querystring-parser-1.2.4 ray-1.5.0 rdflib-6.0.2 redis-3.5.3 sacremoses-0.0.46 sentence-transformers-2.1.0 sentencepiece-0.1.96 seqeval-1.2.2 smmap-5.0.0 sniffio-1.2.0 sqlalchemy-utils-0.37.9 starlette-0.16.0 tika-1.24 tokenizers-0.10.3 tox-3.24.4 transformers-4.7.0 typing-inspect-0.7.1 ujson-4.2.0 uvicorn-0.15.0 uvloop-0.14.0 validators-0.18.2 virtualenv-20.10.0 weaviate-client-2.5.0 websocket-client-1.2.1 yarl-1.7.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmRuhTQ7A6Nh"
      },
      "source": [
        "from haystack.utils import convert_files_to_dicts, fetch_archive_from_http, clean_wiki_text\n",
        "from haystack.nodes import Seq2SeqGenerator"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3dSo7ZtA6Nl"
      },
      "source": [
        "### Document Store\n",
        "\n",
        "FAISS is a library for efficient similarity search on a cluster of dense vectors.\n",
        "The `FAISSDocumentStore` uses a SQL(SQLite in-memory be default) database under-the-hood\n",
        "to store the document text and other meta data. The vector embeddings of the text are\n",
        "indexed on a FAISS Index that later is queried for searching answers.\n",
        "The default flavour of FAISSDocumentStore is \"Flat\" but can also be set to \"HNSW\" for\n",
        "faster search at the expense of some accuracy. Just set the faiss_index_factor_str argument in the constructor.\n",
        "For more info on which suits your use case: https://github.com/facebookresearch/faiss/wiki/Guidelines-to-choose-an-index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cYgDJmrA6Nv",
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44aef483-c9cf-4889-c985-26cd2554b050"
      },
      "source": [
        "# from haystack.document_stores import FAISSDocumentStore\n",
        "# document_store = FAISSDocumentStore(vector_dim=128, faiss_index_factory_str=\"Flat\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<haystack.document_stores.faiss.FAISSDocumentStore at 0x7f4cfa33e350>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gM45JHcbRKjL",
        "outputId": "409ff6ec-5a0d-4754-e148-0ff577bfe1a7"
      },
      "source": [
        "# Download and install Ealstic Search not required for windows\n",
        "# ! wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.9.2-linux-x86_64.tar.gz -q\n",
        "# ! tar -xzf elasticsearch-7.9.2-linux-x86_64.tar.gz\n",
        "# ! chown -R daemon:daemon elasticsearch-7.9.2\n",
        "\n",
        "import os\n",
        "from subprocess import Popen, PIPE, STDOUT\n",
        "es_server = Popen(['elasticsearch-7.9.2/bin/elasticsearch'],\n",
        "                   stdout=PIPE, stderr=STDOUT,\n",
        "                   preexec_fn=lambda: os.setuid(1)  # as daemon\n",
        "                  )\n",
        "# wait until ES has started\n",
        "! sleep 30\n",
        "\n",
        "from haystack.utils import launch_es\n",
        "launch_es()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Tried to start Elasticsearch through Docker but this failed. It is likely that there is already an existing Elasticsearch instance running. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8e67J21sV5Fs"
      },
      "source": [
        "from haystack.document_stores import ElasticsearchDocumentStore\n",
        "document_store = ElasticsearchDocumentStore(host=\"localhost\", username=\"\", password=\"\",\n",
        "                                            index=\"document\", return_embedding=True)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06LatTJBA6N0",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Cleaning & indexing documents\n",
        "\n",
        "Similarly to the previous tutorials, we download, convert and index some Game of Thrones articles to our DocumentStore"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqKnu6wxA6N1",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "# Let's first get some files that we want to use\n",
        "doc_dir = \"data/article_txt_got\"\n",
        "s3_url = \"https://s3.eu-central-1.amazonaws.com/deepset.ai-farm-qa/datasets/documents/wiki_gameofthrones_txt.zip\"\n",
        "fetch_archive_from_http(url=s3_url, output_dir=doc_dir)\n",
        "\n",
        "# Convert files to dicts\n",
        "dicts = convert_files_to_dicts(dir_path=doc_dir, clean_func=clean_wiki_text, split_paragraphs=True)\n",
        "    \n",
        "# Now, let's write the dicts containing documents to our DB.\n",
        "document_store.write_documents(dicts)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgjedxx_A6N6"
      },
      "source": [
        "### Initalize Retriever and Reader/Generator\n",
        "\n",
        "#### Retriever\n",
        "\n",
        "**Here:** We use a `RetribertRetriever` and we invoke `update_embeddings` to index the embeddings of documents in the `FAISSDocumentStore`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFwiPP60A6N7",
        "pycharm": {
          "is_executing": true
        }
      },
      "source": [
        "# from haystack.nodes import EmbeddingRetriever\n",
        "\n",
        "# retriever = EmbeddingRetriever(document_store=document_store,\n",
        "#                                embedding_model=\"yjernite/retribert-base-uncased\",\n",
        "#                                model_format=\"retribert\")\n",
        "\n",
        "# document_store.update_embeddings(retriever)\n",
        "\n",
        "from haystack.nodes import DensePassageRetriever\n",
        "retriever = DensePassageRetriever(document_store=document_store,\n",
        "                                  query_embedding_model=\"facebook/dpr-question_encoder-single-nq-base\",\n",
        "                                  passage_embedding_model=\"facebook/dpr-ctx_encoder-single-nq-base\",\n",
        "                                  max_seq_len_query=64,\n",
        "                                  max_seq_len_passage=256,\n",
        "                                  batch_size=16,\n",
        "                                  use_gpu=True,\n",
        "                                  embed_title=True,\n",
        "                                  use_fast_tokenizers=True)\n",
        "# document_store.update_embeddings(retriever)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFPrlXyIOXIT"
      },
      "source": [
        "# document_store.save(index_path='FAISS_GoT')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqhzC31SOmNp",
        "outputId": "bf6f87d6-c8b8-4775-e4ba-8c755513856e"
      },
      "source": [
        "# document_store.load(index_path='FAISS_GoT')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<haystack.document_stores.faiss.FAISSDocumentStore at 0x7f4cf7edd550>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMlVEnJ2NkZZ"
      },
      "source": [
        "Before we blindly use the `RetribertRetriever` let's empirically test it to make sure a simple search indeed finds the relevant documents."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpu-t9rndgpe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fa83fa9-025f-494a-f357-fc433551b398"
      },
      "source": [
        "from haystack.utils import print_documents\n",
        "from haystack.pipelines import DocumentSearchPipeline\n",
        "\n",
        "p_retrieval = DocumentSearchPipeline(retriever)\n",
        "res = p_retrieval.run(\n",
        "    query=\"Tell me something about Arya Stark?\",\n",
        "    params={\"Retriever\": {\"top_k\": 10}}\n",
        ")\n",
        "print_documents(res, max_text_len=512)\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Tell me something about Arya Stark?\n",
            "\n",
            "{   'content': '\\n'\n",
            "               '=== Background ===\\n'\n",
            "               'Arya is the third child and younger daughter of Eddard and '\n",
            "               'Catelyn Stark and is nine years old at the beginning of the '\n",
            "               'book series.  She has five siblings: an older brother Robb, an '\n",
            "               'older sister Sansa, two younger brothers Bran and Rickon, and '\n",
            "               'an older illegitimate half-brother, Jon Snow.',\n",
            "    'name': '43_Arya_Stark.txt'}\n",
            "\n",
            "{   'content': '\\n'\n",
            "               \"===''A Feast for Crows''===\\n\"\n",
            "               \"After Lysa's death, Sansa becomes mistress of the Eyrie and \"\n",
            "               \"still pretends to be Baelish's illegitimate daughter, Alayne \"\n",
            "               'Stone. Baelish successfully pacifies the lords of the Vale, '\n",
            "               \"who suspected Baelish's hand in Lysa's death. Afterwards, \"\n",
            "               'Baelish reveals to Sansa his plans to eventually marry her to '\n",
            "               'the heir to the Vale, Harrold Hardyng, and his long-range '\n",
            "               'plans to reveal her true identity and reclaim the North. Sansa '\n",
            "               'acts as a mother figure to Robert Arryn, caring for him '\n",
            "               'after...',\n",
            "    'name': '332_Sansa_Stark.txt'}\n",
            "\n",
            "{   'content': '\\n'\n",
            "               '== TV adaptation ==\\n'\n",
            "               'Isaac Hempstead Wright plays the role of Bran Stark in the '\n",
            "               'television series.\\n'\n",
            "               'Bran Stark is played by Isaac Hempstead Wright in the '\n",
            "               'television adaption of the series of books.',\n",
            "    'name': '331_Bran_Stark.txt'}\n",
            "\n",
            "{   'content': \"'''Brandon Stark''', typically called '''Bran''', is a \"\n",
            "               \"fictional character in the ''A Song of Ice and Fire'' series \"\n",
            "               'of epic fantasy novels by American author George R. R. Martin, '\n",
            "               \"and its television adaptation ''Game of Thrones''.\\n\"\n",
            "               \"Introduced in 1996's ''A Game of Thrones'', Bran is the second \"\n",
            "               'son and fourth child of Lord Eddard and Lady Catelyn Stark of '\n",
            "               'Winterfell, the ancient capital of the North of the fictional '\n",
            "               \"kingdom of Westeros.  He subsequently appeared in ''A Clash of \"\n",
            "               \"Kings'' (1998) and ''A Storm of ...\",\n",
            "    'name': '331_Bran_Stark.txt'}\n",
            "\n",
            "{   'content': '\\n'\n",
            "               '==Character and appearances==\\n'\n",
            "               'Sansa Stark is the second child and elder daughter of Eddard '\n",
            "               'Stark and Catelyn Stark. She was born and raised in '\n",
            "               'Winterfell, until leaving with her father and sister at the '\n",
            "               'beginning of the series. She was raised with a younger sister '\n",
            "               'Arya Stark, two younger brothers Rickon Stark and Bran Stark, '\n",
            "               'as well as an older brother Robb Stark, and an older '\n",
            "               'illegitimate half-brother, Jon Snow.\\n'\n",
            "               \"Raised as a lady, Sansa is traditionally feminine. Sansa's \"\n",
            "               'interests are music, poetry, and si...',\n",
            "    'name': '332_Sansa_Stark.txt'}\n",
            "\n",
            "{   'content': '\\n'\n",
            "               '==Character profile==\\n'\n",
            "               'Olenna Tyrell, also known as the Queen of Thorns, is a former '\n",
            "               'Redwyne and the mother of Mace Tyrell. She is described as a '\n",
            "               'wizened and cunning old woman with a wicked wit and a sharp '\n",
            "               'tongue, and is known for openly stating her opinion.\\n'\n",
            "               'Olenna is not a point of view character in the novels, so her '\n",
            "               'actions are witnessed and interpreted through the eyes of '\n",
            "               'other people, such as Sansa Stark and Cersei Lannister. Olenna '\n",
            "               'is mostly a background character in the novels.',\n",
            "    'name': '218_Olenna_Tyrell.txt'}\n",
            "\n",
            "{   'content': '\\n'\n",
            "               '== Characters ==\\n'\n",
            "               'The story is narrated  from the point of view  of 12 '\n",
            "               'characters and a one-off prologue point of view. Unlike its '\n",
            "               'predecessors, the fourth novel follows numerous minor '\n",
            "               'characters as well.\\n'\n",
            "               '* Prologue: Pate, a novice of the Citadel in Oldtown\\n'\n",
            "               '* Cersei Lannister, The Queen Regent\\n'\n",
            "               '* Ser Jaime Lannister, Lord Commander of the Kingsguard\\n'\n",
            "               '* Brienne, Maid of Tarth, a young warrior woman searching for '\n",
            "               'Sansa and Arya Stark\\n'\n",
            "               \"* Sansa Stark, pretending to be Petyr Baelish's  daughter \"\n",
            "               '\"Alayne Stone\" (her ...',\n",
            "    'name': '202_A_Feast_for_Crows.txt'}\n",
            "\n",
            "{   'content': '\\n'\n",
            "               '=== Description ===\\n'\n",
            "               'Arya is left-handed and talented in sums and housekeeping, and '\n",
            "               'is excellent at horse-riding.  In contrast to her more praised '\n",
            "               'sister Sansa, who favors activities traditionally befitting a '\n",
            "               'noblewoman and expresses disdain for outdoor activities, Arya '\n",
            "               'shows no interest in dancing, singing and sewing, and revels '\n",
            "               'in fighting and exploring, much to the chagrin of her mother '\n",
            "               'and household tutor Septa Mordane.  She is described as '\n",
            "               '\"wolf-blooded\", blunt, impulsive and \"always difficult to '\n",
            "               'tame\"...',\n",
            "    'name': '43_Arya_Stark.txt'}\n",
            "\n",
            "{   'content': '\\n'\n",
            "               '====Season 7====\\n'\n",
            "               'Bran returns to Winterfell, which has been rebuilt and '\n",
            "               'reoccupied by the remaining Starks. Jon Snow has traveled to '\n",
            "               'Dragonstone to meet with Daenerys Targaryen, after which he is '\n",
            "               'finally reunited at Winterfell with Sansa and Arya, who are '\n",
            "               \"both concerned by Bran's knowledge about their tribulations \"\n",
            "               \"following Ned's execution. Littlefinger gives Bran a Valyrian \"\n",
            "               \"steel dagger (the one used by Bran's would-be assassin in \"\n",
            "               'season one), which Bran passes to Arya. Meera leaves '\n",
            "               'Winterfell to return t...',\n",
            "    'name': '331_Bran_Stark.txt'}\n",
            "\n",
            "{   'content': \"'''Arya Stark''' is a fictional character in American author \"\n",
            "               \"George R. R. Martin's ''A Song of Ice and Fire'' epic fantasy \"\n",
            "               'novel series.  She is a prominent point of view character in '\n",
            "               'the novels with the third most viewpoint chapters, and is the '\n",
            "               'only viewpoint character to have appeared in every published '\n",
            "               'book of the series.\\n'\n",
            "               \"Introduced in 1996's ''A Game of Thrones'', Arya is the third \"\n",
            "               'child and younger daughter of Lord Eddard Stark and his wife '\n",
            "               'Lady Catelyn Stark.  She is tomboyish, headstrong, feisty, '\n",
            "               'ind...',\n",
            "    'name': '43_Arya_Stark.txt'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnVR28OXA6OA"
      },
      "source": [
        "#### Reader/Generator\n",
        "\n",
        "Similar to previous Tutorials we now initalize our reader/generator.\n",
        "\n",
        "Here we use a `Seq2SeqGenerator` with the *yjernite/bart_eli5* model (see: https://huggingface.co/yjernite/bart_eli5)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyIuWVwhA6OB"
      },
      "source": [
        "generator = Seq2SeqGenerator(model_name_or_path=\"yjernite/bart_eli5\")"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unhLD18yA6OF"
      },
      "source": [
        "### Pipeline\n",
        "\n",
        "With a Haystack `Pipeline` you can stick together your building blocks to a search pipeline.\n",
        "Under the hood, `Pipelines` are Directed Acyclic Graphs (DAGs) that you can easily customize for your own use cases.\n",
        "To speed things up, Haystack also comes with a few predefined Pipelines. One of them is the `GenerativeQAPipeline` that combines a retriever and a reader/generator to answer our questions.\n",
        "You can learn more about `Pipelines` in the [docs](https://haystack.deepset.ai/docs/latest/pipelinesmd)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TssPQyzWA6OG"
      },
      "source": [
        "from haystack.pipelines import GenerativeQAPipeline\n",
        "pipe = GenerativeQAPipeline(generator, retriever)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXlBBxKXA6OL"
      },
      "source": [
        "## Voilà! Ask a question!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zi97Hif2A6OM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47a7cedd-12e7-44d3-e37e-eaf9a77279c0"
      },
      "source": [
        "print_documents(pipe.run(\n",
        "    query=\"What is Arya's sister's name?\",\n",
        "    params={\"Retriever\": {\"top_k\": 1}}\n",
        "))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: What is Arya's sister's name?\n",
            "\n",
            "{   'content': '\\n'\n",
            "               '=== Background ===\\n'\n",
            "               'Arya is the third child and younger daughter of Eddard and '\n",
            "               'Catelyn Stark and is nine years old at the beginning of the '\n",
            "               'book series.  She has five siblings: an older brother Robb, an '\n",
            "               'older sister Sansa, two younger brothers Bran and Rickon, and '\n",
            "               'an older illegitimate half-brother, Jon Snow.',\n",
            "    'name': '43_Arya_Stark.txt'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvHb8SvMblw9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f3054c7-4975-48ab-81c7-de811bb7be7c"
      },
      "source": [
        "print_documents(pipe.run(query=\"Who was the luckiest character in the show?\", params={\"Retriever\": {\"top_k\": 1}}))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Who was the luckiest character in the show?\n",
            "\n",
            "{   'content': '\\n'\n",
            "               '==Production==\\n'\n",
            "               \"As with the previous episode, the show's opening title \"\n",
            "               'sequence is modified to depict the characters in their '\n",
            "               'role-playing garb, while the soundtrack has been altered to '\n",
            "               \"include the penis-themed chorus singing to the ''Game of \"\n",
            "               \"Thrones'' opening theme introduced in the previous episode. \"\n",
            "               'Series co-creators Trey Parker and Matt Stone said that they '\n",
            "               'experimented with different styles of opening sequences before '\n",
            "               'settling on the penis-themed chorus version; a Japanese '\n",
            "               'Princess Kenny opening sequence was one of the original ideas.',\n",
            "    'name': '101_Titties_and_Dragons.txt'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "VGaGgdB1M5Tn"
      },
      "source": [
        "## About us\n",
        "\n",
        "This [Haystack](https://github.com/deepset-ai/haystack/) notebook was made with love by [deepset](https://deepset.ai/) in Berlin, Germany\n",
        "\n",
        "We bring NLP to the industry via open source!\n",
        "Our focus: Industry specific language models & large scale QA systems.\n",
        "\n",
        "Some of our other work:\n",
        "- [German BERT](https://deepset.ai/german-bert)\n",
        "- [GermanQuAD and GermanDPR](https://deepset.ai/germanquad)\n",
        "- [FARM](https://github.com/deepset-ai/FARM)\n",
        "\n",
        "Get in touch:\n",
        "[Twitter](https://twitter.com/deepset_ai) | [LinkedIn](https://www.linkedin.com/company/deepset-ai/) | [Slack](https://haystack.deepset.ai/community/join) | [GitHub Discussions](https://github.com/deepset-ai/haystack/discussions) | [Website](https://deepset.ai)\n",
        "\n",
        "By the way: [we're hiring!](https://www.deepset.ai/jobs)"
      ]
    }
  ]
}